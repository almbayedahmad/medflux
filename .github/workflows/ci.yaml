name: CI

on:
  push:
    branches: [ "**" ]
  pull_request:

permissions:
  contents: read

concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    outputs:
      docs: ${{ steps.filter.outputs.docs }}
      code: ${{ steps.filter.outputs.code }}
      workflows: ${{ steps.filter.outputs.workflows }}
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: |
            docs:
              - '**/*.md'
              - 'docs/**'
            workflows:
              - '.github/**'
            code:
              - 'backend/**'
              - 'core/**'
              - 'shared/**'
              - 'apps/**'
              - 'tools/**'
              - 'tests/**'
              - 'pyproject.toml'
              - 'requirements*.txt'
              - 'Makefile'

  lint:
    name: Lint (pre-commit)
    needs: changes
    if: needs.changes.outputs.docs == 'true' || needs.changes.outputs.code == 'true' || needs.changes.outputs.workflows == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - uses: ./.github/actions/python-setup
      - name: Install pre-commit
        run: pip install pre-commit
      - name: Pre-commit (all files)
        run: SKIP=no-commit-to-branch pre-commit run --all-files --show-diff-on-failure

  static-audits:
    name: Static Audits (legacy + structure)
    needs: changes
    if: needs.changes.outputs.code == 'true' || needs.changes.outputs.workflows == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - name: Install ripgrep
        run: |
          sudo apt-get update
          sudo apt-get install -y ripgrep
      - name: Audit for legacy paths/imports
        shell: bash
        run: |
          set -euo pipefail
          echo "Auditing for legacy paths/imports..."
          if rg -n -S "\\b(connecters|internal_helpers|core_functions|pipeline_workflow)\\b" --glob '!**/CHANGELOG*' --glob '!**/README*'; then
            echo "Found legacy references above. Please remove legacy dirs/imports and use v2 structure/services." >&2
            exit 1
          else
            echo "OK: no legacy references found."
          fi
      - name: Audit for phase-local tests folders
        shell: bash
        run: |
          set -euo pipefail
          echo "Checking for phase-local tests directories..."
          if rg -n -S "phase_\\d\\d_\\w+/tests/" --glob '!**/CHANGELOG*' --glob '!**/README*'; then
            echo "Found phase-local tests references above. Tests must live under root tests/." >&2
            exit 1
          else
            echo "OK: no phase-local tests references."
          fi
      - name: Audit filesystem for phase-local tests directories
        shell: bash
        run: |
          set -euo pipefail
          echo "Scanning filesystem for phase-local tests directories..."
          if find backend/Preprocessing -type d -regex '.*/phase_[0-9][0-9]_[^/]+/tests$' -print -quit | grep -q . ; then
            echo "Found phase-local tests directories in filesystem. Remove them; all tests must be under root tests/." >&2
            find backend/Preprocessing -type d -regex '.*/phase_[0-9][0-9]_[^/]+/tests$' -print >&2 || true
            exit 1
          else
            echo "OK: no phase-local tests directories present."
          fi
      - name: Audit for tracked cache/backup/log files
        shell: bash
        run: |
          set -euo pipefail
          echo "Checking tracked files for caches/backups/logs..."
          BAD=$(git ls-files | rg -n "(\\.pytest_cache/|\\.benchmarks/|\\.bak$|^logs/)") || true
          if [ -n "$BAD" ]; then
            echo "Found tracked cache/backup/log files:" >&2
            echo "$BAD" >&2
            echo "Please remove these from version control." >&2
            exit 1
          else
            echo "OK: no tracked cache/backup/log files."
          fi

  typecheck:
    name: Type Check (mypy)
    needs: changes
    if: needs.changes.outputs.code == 'true'
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/python-setup
      - run: pip install mypy
      - name: Run mypy (warn-only)
        run: |
          mypy backend core || echo "mypy completed with warnings"

  tests:
    name: Tests (matrix)
    needs: changes
    if: needs.changes.outputs.code == 'true'
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest]
        python-version: ['3.11','3.12']
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/python-setup
        with:
          python-version: ${{ matrix.python-version }}
      - name: Run tests with coverage (>=50%)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest -q --maxfail=1 --disable-warnings --cov=. --cov-report=xml --cov-fail-under=50 --junitxml=pytest-junit.xml
      - name: Upload coverage
        if: matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}
          path: coverage.xml
      - name: Upload JUnit report
        if: always() && matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: junit-${{ matrix.python-version }}
          path: pytest-junit.xml
      - name: Coverage summary
        if: matrix.os == 'ubuntu-latest'
        env:
          PYVER: ${{ matrix.python-version }}
        shell: bash
        run: |
          python - <<'PY'
          import os, xml.etree.ElementTree as ET
          root = ET.parse('coverage.xml').getroot()
          rate = float(root.get('line-rate', '0')) * 100.0
          py = os.getenv('PYVER','')
          print(f'Coverage (Python {py}): {rate:.2f}%')
          summary = os.getenv('GITHUB_STEP_SUMMARY')
          if summary:
              with open(summary,'a',encoding='utf-8') as f:
                  f.write(f"### Coverage (Python {py})\n\n{rate:.2f}%\n")
          PY
      - name: Upload to Codecov (optional)
        if: matrix.os == 'ubuntu-latest'
        uses: codecov/codecov-action@v4
        with:
          files: coverage.xml
          flags: py${{ matrix.python-version }}
          fail_ci_if_error: false
          token: ${{ secrets.CODECOV_TOKEN }}

  schema-validation:
    name: Schema & Docs
    needs: changes
    if: needs.changes.outputs.code == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - uses: ./.github/actions/python-setup
      - name: Verify schema version
        run: python tools/schema/verify_schema_version.py
      - name: Validate schemas
        run: python tools/validation/validate_schemas.py
      - name: Schema compatibility vs last tag
        run: python tools/schema/check_compat.py
      - name: Check schema docs
        run: python tools/schema/generate_schema_docs.py --check

  policy-version:
    name: Policy & Version Checks
    needs: changes
    if: needs.changes.outputs.code == 'true' || needs.changes.outputs.workflows == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with: { fetch-depth: 0 }
      - uses: ./.github/actions/python-setup
      - name: Version info
        run: python -m core.versioning
      - name: Verify version consistency
        run: python tools/versioning/verify_version.py
      - name: Verify migrations numbering
        run: python tools/schema/verify_migrations.py
      - name: Verify changelog on version bump (PRs only)
        if: ${{ github.event_name == 'pull_request' }}
        run: python tools/ci/verify_changelog_for_version_bump.py
      - name: Enforce commit semantics vs VERSION (PRs only)
        if: ${{ github.event_name == 'pull_request' }}
        run: python tools/ci/verify_commit_semantics_vs_version.py

  package-parity:
    name: Package Parity
    needs: [changes, tests]
    if: needs.changes.outputs.code == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/python-setup
      - name: Build and check parity
        shell: bash
        run: |
          python -m pip install --upgrade build
          python -m build --sdist --wheel
          python -m pip install --upgrade twine
          python -m twine check dist/*
          python -m venv .pkgvenv
          source .pkgvenv/bin/activate
          python -m pip install dist/*.whl
          INST=$(python - <<'PY'
          import core.versioning as v
          print(v.__version__)
          PY
          )
          FILEV=$(cat core/versioning/VERSION | tr -d '\n')
          if [ "$INST" != "$FILEV" ]; then
            echo "Installed version $INST does not match file version $FILEV" >&2
            exit 1
          fi
          echo "OK: installed=$INST matches file=$FILEV"
      - name: Upload dist artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-packages
          path: dist/*

  smoke:
    name: Smoke CLI & Logs
    needs: [changes, schema-validation]
    if: needs.changes.outputs.code == 'true'
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: .
      MEDFLUX_LOG_FORMAT: json
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/python-setup
      - name: Generate sample logs
        shell: bash
        env:
          MEDFLUX_LOG_PROFILE: dev
        run: |
          python - <<'PY'
          import logging
          from core.logging import configure_logging, configure_log_destination
          configure_logging(force=True)
          p=configure_log_destination('CI_RUN','phase_demo')
          log=logging.getLogger('medflux.ci')
          log.info('hello', extra={'run_id':'CI_RUN','phase':'phase_demo'})
          log.warning('warn', extra={'run_id':'CI_RUN','phase':'phase_demo','code':'CI-W001'})
          print(str(p))
          PY
      - name: Validate log records
        run: python tools/logs/validate_records.py --root logs --glob "**/phase_demo.jsonl" --min-context 0.9
      - name: No stray prints in runtime code
        run: python tools/ci/check_no_prints.py --roots backend core
      - name: Smoke detect_type CLI
        shell: bash
        env:
          MEDFLUX_LOG_PROFILE: dev
        run: |
          echo "hello" > sample.txt
          python -m core.cli.medflux --log-level INFO --log-json --log-stderr \
            phase-detect --inputs sample.txt --output-root ./ci_artifacts/detect
      - name: Validate detect_type logs
        run: python tools/logs/validate_records.py --root logs --glob "**/phase_00_detect_type.jsonl" --min-context 0.95
      - name: Validate detect_type CLI output via schema
        run: python tools/validation/validate_phase.py phase_00_detect_type output ci_artifacts/detect/detect_type_unified_document.json --log-json
      - name: Validate detect_type saved artifacts
        run: |
          python tools/validation/validate_artifacts.py --auto \
            ci_artifacts/detect/detect_type_unified_document.json \
            ci_artifacts/detect/detect_type_stage_stats.json
      - name: Smoke encoding CLI and validate
        shell: bash
        env:
          MEDFLUX_LOG_PROFILE: dev
        run: |
          python -m core.cli.medflux --log-level INFO --log-json --log-stderr \
            phase-encoding --inputs sample.txt --output-root ./ci_artifacts/encoding || true
          python tools/validation/validate_phase.py phase_01_encoding output ci_artifacts/encoding/encoding_unified_document.json --log-json
      - name: Smoke readers CLI and validate
        shell: bash
        env:
          MEDFLUX_LOG_PROFILE: dev
        run: |
          python -m core.cli.medflux --log-level INFO --log-json --log-stderr \
            phase-readers --inputs sample.txt --output-root ./ci_artifacts/readers || true
          python tools/validation/validate_phase.py phase_02_readers output ci_artifacts/readers/readers_doc_meta.json --log-json
      - name: Consolidated validation report
        run: |
          python tools/validation/validation_report.py \
            --phase-output phase_00_detect_type:ci_artifacts/detect/detect_type_unified_document.json \
            --logs-root logs \
            --artifact ci_artifacts/detect/detect_type_unified_document.json \
            --artifact ci_artifacts/detect/detect_type_stage_stats.json \
            --out-json validation_report.json \
            --out-md validation_report.md \
            --max-fail-rate 0.0 \
            --fail-on-codes VL-E010,VL-E002
      - name: Samples smoke (first 3 phases)
        shell: bash
        env:
          MEDFLUX_LOG_PROFILE: dev
        run: |
          python tools/smoke/run_samples_smoke.py --phases detect encoding readers --out-root .artifacts/smoke --limit 2
          echo "Smoke summary:" && cat .artifacts/smoke/smoke_summary.json || true
      - name: Upload smoke artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-samples
          path: .artifacts/smoke/**
      - name: Upload validation report
        uses: actions/upload-artifact@v4
        with:
          name: validation-report
          path: |
            validation_report.json
            validation_report.md

  integration:
    name: Integration Tests (API)
    needs: changes
    if: needs.changes.outputs.code == 'true'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/python-setup
      - name: Install integration deps
        run: |
          python -m pip install httpx
      - name: Run integration tests
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          pytest -q -m integration --disable-warnings --maxfail=1 --junitxml=pytest-junit-int.xml
      - name: Upload JUnit report (integration)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: junit-integration
          path: pytest-junit-int.xml

  security:
    name: Security (pip-audit, bandit)
    needs: changes
    if: needs.changes.outputs.code == 'true'
    runs-on: ubuntu-latest
    continue-on-error: true
    steps:
      - uses: actions/checkout@v4
      - uses: ./.github/actions/python-setup
      - name: pip-audit
        run: |
          python -m pip install pip-audit
          pip-audit -r requirements.txt -r requirements-dev.txt || true
      - name: bandit
        run: |
          python -m pip install bandit
          bandit -r backend core -x tests -q || true
      - name: gitleaks (secrets scan)
        uses: gitleaks/gitleaks-action@v2
        with:
          args: detect --no-banner --redact --source . || true
